\section{Code Implementation}


The main goal of the project was to not only create a working code but the code had to be reusable as well.
To match these design criteria we have chosen for an object orientated approach in python and made full use of the inheritance features provided by the language.

To speed up the computations a lot we used the python library \verb|multiprocessing| to create multiple workers who can run in parallel, this is very easily created in python and it speeds your code up by a factor 8 (If you have 8 threads running on your computer).


\subsection{Code structure}

A good program always starts out with a good structure. 
For this we decided to split the code up in a number of  packages , each of these packages has a typical task and several classes in it.
As on example, there is a Worker package, this package includes everything to create new workers to parallellise the computations.


\subsection{Solving the Differential Equation}

For solving a differential equation of the form
\begin{equation}
\dfrac{d }{dt} Y(x,t) = f(x,t)
\end{equation}
We need a method to integrate the function $ f(x,t) $.
In this paper we implemented the Runge Kutta method of order 4 to do this.
The explicit formula for this method is given by
\begin{equation}
y_{n+1} = y_n + \frac{h}{6}(k_{1} + 2k_{2} + 2k_{3} + k_{4})
\end{equation}
where $ k_i $ are given by
\begin{align*}
k_1 &= f(t_n, y_n),\\
k_2 &= f(t_n + \tfrac{h}{2}, y_n + \tfrac{h}{2} k_1),\\
k_3 &= f(t_n + \tfrac{h}{2}, y_n + \tfrac{h}{2} k_2),\\
k_4 &= f(t_n + h, y_n + hk_3).
\end{align*}
This method is of fourth order, this means that the error of the method drops as a fourth order function.
The package Integrators was responsible for this, as will be clear from the code, we wrote the Runge Kutta solver as general as possible.
When provided by a correct butcher matrix, the order of the method could be changed.

\subsection{Finding the Eigenvalues}
Solving the differential equation is the easy part of the assignment.
Finding the eigenvalues was the real challenge and it was the task of the worker class.

Finding an eigenvalue comes basically down of finding a root of the function
\begin{equation}
F_{end}(\omega^2;\sigma,K,g),
\end{equation}
which gives the function value of the differential equation at the position 1.
We created a couple of workers each with its own way of finding these roots.
These workers could than be run independently of each other and search for roots in it's own variable subspace.

Lets now look in more detail to the differed ways the workers try to find these roots.

\subsubsection{The Simple Stepping Worker}

The first and easiest to implement worker is the \verb|workerSimple|.
A simplified version of the  algorithm it uses to find the roots is described in Algorithm \ref{alg:stupid}.
The basic idea is to start with a large enough value for $ \omega $ and decrease it step by step.
If you step over a root (If the sign of the end point flips) go back and decrease the step size.
repeat this process till you are close enough to the zero.
For finding the next root just step away till you are out of the tolerance boundaries and repeat the process till you find a next point using the same convention.
A huge downsides of this algorithm that it is slow and it relies on the initial conditions of the differential equations.
A main advantage of the method is that it is guaranteed to converge toward a root and it is easy to understand.

\begin{algorithm}[h!]
 initialization\;
 guess = 1\;
 shrinksize = 0.9\;
 overcount = 1\;
 endP = endPoint(guess)\;
	 \While{Pend $ \leq $0}{
		guess = guess*10\;
		endP = endPoint(guess)\:
	}
	 \While{Pend $ \geq $MAXTOL}{
		previous = guess\;
		guess = previous * shrinksize\;
		endP = endPoint(guess)\;
	
	\If{abs(endP)$ \leq $MAXTOL}{
	   break\;
	   }
	 \If{endP$ \leq $0}{
	 overCount = overCount +1\;
	 shrinksize = shrinksize + 9/(10**overCount)\;
	 }
  }
 
 \caption{The simplified version of the simple stepping algorithm, the step size is far from ideal and the convergens is sometimes very slow but it is always guaranteed to converges.}
 \label{alg:stupid}
\end{algorithm}

\subsubsection{The Non Linear Worker}

An other approach we tried was to use a non linear solver already implemented in python.
The worker doing so is the workerNLS.
I tried out some predefined non linear solvers but found that the Anderson mixing algorithm worked best for this problem.
The big problem when using this solver was to guess the starting value  $ \omega $ for the iterative solver.
One of our ideas was to calculate some roots randomly, based on these than calculate the interpolated polynomial trough these points and based on this do a guess for the next root.
This however was hard to implement and did not work all of the time, so we moved away from this approach.
However this method works good if we only need to find the first root and start out by a large enough guess for $ \omega $.
The advantage of this method was it's speed.
The disadvantage was finding higher order roots, and sometimes the algorithm did not converges at all.


\subsubsection{The Worker2 worker}

This was one of the early attempts to find the eigenvalues of the equation.
The worker tries to estimate the derivative of the function so he doesn't need to calculate it.
It turned out that this was not a stable way to find good eigenvalues for the wave equation. 



